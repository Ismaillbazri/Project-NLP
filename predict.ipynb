{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "529e7784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79c01798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "Precision: 0.98\n",
      "Recall: 0.99\n",
      "F1-score: 0.98\n",
      "-------------------------------------------\n",
      "Equipment Name:  réacteurs \n",
      "Predicted Name: INOX_REACTOR, Confidence: 0.9745685809048135\n",
      "Predicted Name: PREPARATION_VESSEL, Confidence: 0.006181249632191923\n",
      "Predicted Name: BOTTLE_FILLING_MACHINE, Confidence: 0.0029160785598131285\n",
      "-------------------------------------------\n",
      "Equipment Name: Transformateurs Triphasé (T13)    \n",
      "Predicted Name: TRANSFORMER, Confidence: 0.9953646596363122\n",
      "Predicted Name: BOTTLE_FILLING_MACHINE, Confidence: 0.0006705574476757722\n",
      "Predicted Name: MELTING_POT, Confidence: 0.0005835853483289741\n",
      "-------------------------------------------\n",
      "Equipment Name: 1 Conge À Sirop ppp Électrique 123\n",
      "Predicted Name: MELTING_POT, Confidence: 0.9426550956526978\n",
      "Predicted Name: TRANSFORMER, Confidence: 0.025044844403544566\n",
      "Predicted Name: BOTTLE_FILLING_MACHINE, Confidence: 0.004718479860022788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "\n",
    "# Chargement des données\n",
    "\n",
    "df = pd.read_excel('./extract_normalised_name_fr_training_data.xlsx')\n",
    "\n",
    "\n",
    "# Extraire chacune des colonnes dans des variables X et Y\n",
    "\n",
    "X = df['designation_fr']\n",
    "Y = df['normalised_name']\n",
    "\n",
    "\n",
    "# Tokenizer notre data\n",
    "\n",
    "X = X.apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# Réduction des mots à leur racines/formes de base\n",
    "\n",
    "stemmer = SnowballStemmer('french')\n",
    "X = X.apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "\n",
    "# Rattacher les mots séparés en un seul text\n",
    "\n",
    "X = X.apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Vectoriser le texte avec CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Export de notre vectorizer pour réutilisation directe\n",
    "\n",
    "# with open('trained_Nlp_vectorizer.pkl', 'wb') as file:\n",
    "#      pickle.dump(vectorizer, file)\n",
    "\n",
    "        \n",
    "#Séparation de nos données en données d'entraînement et données de test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Instanciation du model ici nous allons utiliser la regression logistique avec une régularisation l2 pour éviter l'overfitting\n",
    "\n",
    "clf = LogisticRegression(penalty='l2')\n",
    "\n",
    "\n",
    "# Entrainement du modèle \n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Export du modèle pour réutilisation directe \n",
    "\n",
    "# with open('trained_Nlp_model.pkl', 'wb') as file:\n",
    "#      pickle.dump(clf, file)\n",
    "        \n",
    "# Evaluation du modéle\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# calcul des metrics :  accuracy, precision, recall, et F1-score\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "f1_score = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "# Affichage des metrics calculées\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1-score: {:.2f}\".format(f1_score))\n",
    "\n",
    "# Fonction predict pour tester notre modele \n",
    "\n",
    "def predict(name):\n",
    "    # refaire les mêmes traitements sur le nom d'équipements qu'on veut normaliser\n",
    "    tokens = word_tokenize(name.lower())\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    preprocessed_name = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    # Vectoriser le texte avec CountVectorizer\n",
    "    \n",
    "    X_test = vectorizer.transform([preprocessed_name])\n",
    "    \n",
    "   # Prédire à l'aide du model entrainé\n",
    "\n",
    "    predictions = [(label, prob) for label, prob in zip(clf.classes_,  clf.predict_proba(X_test)[0])]\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "  \n",
    "    predictions = predictions[:3] # J'ai choisi d'afficher la liste des trois premiers classes d'apprtenance avec leurs probabilités\n",
    "       \n",
    "    if predictions:\n",
    "        return predictions\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Test\n",
    "\n",
    "equipment_names = [' réacteurs ', 'Transformateurs Triphasé (T13)    ', '1 Conge À Sirop ppp Électrique 123']\n",
    "for name in equipment_names:\n",
    "    predicted_names = predict(name)\n",
    "    if predicted_names is not None:\n",
    "        print(\"-------------------------------------------\")\n",
    "        print(f\"Equipment Name: {name}\")\n",
    "        for prediction in predicted_names:\n",
    "            print(f\"Predicted Name: {prediction[0]}, Confidence: {prediction[1]}\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d27c4200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pltk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
